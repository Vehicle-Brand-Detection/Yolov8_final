{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection using Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 Maruti Suzuki, 113.8ms\n",
      "Speed: 8.0ms preprocess, 113.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 Maruti Suzuki, 174.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.4ms preprocess, 174.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 (no detections), 120.7ms\n",
      "Speed: 0.0ms preprocess, 120.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 2 Maruti Suzukis, 129.6ms\n",
      "Speed: 0.0ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 2 Maruti Suzukis, 120.5ms\n",
      "Speed: 0.0ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5., 5.]) Data\n",
      "\n",
      "\n",
      "tensor([5., 5.]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 2 Maruti Suzukis, 129.5ms\n",
      "Speed: 0.0ms preprocess, 129.5ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 Maruti Suzuki, 121.0ms\n",
      "Speed: 0.0ms preprocess, 121.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5., 5.]) Data\n",
      "\n",
      "\n",
      "tensor([5.]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 Maruti Suzuki, 112.1ms\n",
      "Speed: 0.0ms preprocess, 112.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 (no detections), 128.6ms\n",
      "Speed: 0.0ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 Maruti Suzuki, 128.6ms\n",
      "Speed: 0.0ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 Maruti Suzuki, 121.5ms\n",
      "Speed: 0.0ms preprocess, 121.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([5.]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 Maruti Suzuki, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 Maruti Suzuki, 120.7ms\n",
      "Speed: 0.0ms preprocess, 120.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([5.]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 Maruti Suzuki, 165.0ms\n",
      "Speed: 4.3ms preprocess, 165.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 (no detections), 112.3ms\n",
      "Speed: 0.0ms preprocess, 112.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([]) Data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 Maruti Suzuki, 111.2ms\n",
      "Speed: 0.0ms preprocess, 111.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 Maruti Suzuki, 112.5ms\n",
      "Speed: 0.0ms preprocess, 112.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([5.]) Data\n",
      "\n",
      "\n",
      "tensor([5.]) Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Open the video file\n",
    "path = \"1.mp4\"\n",
    "a,b=path.split('.')\n",
    "if b in ['jpeg','jpg','png']:\n",
    "    img=cv2.imread(path)\n",
    "    results = model.predict(img,iou=0.6,conf=0.4)\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "else:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model.predict(frame,conf=0.2)\n",
    "            print()\n",
    "            print(results[0].boxes.cls,\"Data\")\n",
    "            print()\n",
    "            annotated_frame=results[0].plot()\n",
    "            # #,results[0].boxes.data,results[0].boxes.cls\n",
    "            # if len(results[0].boxes.conf)>0:\n",
    "            #     if max(results[0].boxes.conf)>0.4:\n",
    "            #      annotated_frame = results[0].plot(conf=True,labels=True,probs=True)\n",
    "            # else:\n",
    "            #     annotated_frame = results[0].plot(conf=False,labels=False,probs=False)\n",
    "            cv2.namedWindow(\"YOLOv8 Inference\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "            cv2.resizeWindow(\"YOLOv8 Inference\", 1280, 600)\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ultralytics.com/modes/predict/#boxes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
